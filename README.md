# Semantic Segmentation with CNNs and Vision Transformers on the Human Visual Diet Dataset

This project compares the performance and interpretability of three deep learning models â€” ResNet-18, DenseNet-121, and SegFormer (a Vision Transformer) â€” for semantic segmentation on the Human Visual Diet dataset, a benchmark designed to reflect human-like visual experience.

##  Motivation

While CNNs have driven significant progress in vision tasks, they often rely on superficial features and struggle with generalization. This project investigates:

- Can architectures like Vision Transformers perform better on complex, context-rich scenes?
- Do Grad-CAM (for CNNs) and attention maps (for ViTs) show human-aligned reasoning?
- What challenges do models face when trained on more "human-like" data?

##  Project Structure
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ resnet_segmentation.py
â”‚ â”œâ”€â”€ densenet_segmentation.py
â”‚ â””â”€â”€ vit_segformer.py
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ gradcam.py
â”‚ â”œâ”€â”€ attention_visualization.py
â”‚ â””â”€â”€ data_loader.py
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ ResNet.ipynb
â”‚ â”œâ”€â”€ DenseNet-2.ipynb
â”‚ â””â”€â”€ Copy_of_miniViT.ipynb
â”œâ”€â”€ results/
â”‚ â”œâ”€â”€ predictions/
â”‚ â””â”€â”€ visualizations/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


## ðŸ§ª Models

- `ResNet-18` and `DenseNet-121` are used with custom decoder heads for segmentation.
- `SegFormer-B0` (from HuggingFace) is fine-tuned for semantic segmentation.

## ðŸ“Š Metrics

- **Pixel Accuracy**
- **Mean IoU**  
- Visualizations via:
  - Grad-CAM (ResNet, DenseNet)
  - Self-attention maps (SegFormer ViT)

## ðŸ“ˆ Key Results

| Model       | Pixel Acc. | Mean IoU |
|-------------|------------|----------|
| ResNet-18   | ~57%       | ~0.35    |
| DenseNet-121| ~72%       | ~0.50    |
| SegFormer-B0| ~81%       | ~0.60    |

- All models struggle with **edge segmentation**, confuse **floor/wall**, and sometimes rely on **contextual shortcuts**.
- ViT attention maps show more global reasoning, but often attend to irrelevant regions too.


